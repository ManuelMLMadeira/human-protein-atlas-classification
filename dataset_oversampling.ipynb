{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import imgaug as ia\n",
    "from imgaug import augmenters as iaa\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "b3fd4b30584e8fdf544f23d1a56028fa5fa05d1f"
   },
   "outputs": [],
   "source": [
    "SEED = 777\n",
    "SHAPE = (512, 512, 4)\n",
    "DIR = '.'\n",
    "\n",
    "ia.seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# idea: create a new dataset from the one we already have, but where we increase the absolute frequency of the less \n",
    "#       dominant localizations through image augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# building the initial array \"counts\" (list where each entry is the absolute frequency of the correspondent label )\n",
    "\n",
    "path_to_train = DIR + '/train/'\n",
    "train_labels = pd.read_csv(DIR + '/train.csv')\n",
    "\n",
    "label_names = {\n",
    "    0:  \"Nucleoplasm\",  \n",
    "    1:  \"Nuclear membrane\",   \n",
    "    2:  \"Nucleoli\",   \n",
    "    3:  \"Nucleoli fibrillar center\",   \n",
    "    4:  \"Nuclear speckles\",\n",
    "    5:  \"Nuclear bodies\",   \n",
    "    6:  \"Endoplasmic reticulum\",   \n",
    "    7:  \"Golgi apparatus\",   \n",
    "    8:  \"Peroxisomes\",   \n",
    "    9:  \"Endosomes\",   \n",
    "    10:  \"Lysosomes\",   \n",
    "    11:  \"Intermediate filaments\",   \n",
    "    12:  \"Actin filaments\",   \n",
    "    13:  \"Focal adhesion sites\",   \n",
    "    14:  \"Microtubules\",   \n",
    "    15:  \"Microtubule ends\",   \n",
    "    16:  \"Cytokinetic bridge\",   \n",
    "    17:  \"Mitotic spindle\",   \n",
    "    18:  \"Microtubule organizing center\",   \n",
    "    19:  \"Centrosome\",   \n",
    "    20:  \"Lipid droplets\",   \n",
    "    21:  \"Plasma membrane\",   \n",
    "    22:  \"Cell junctions\",   \n",
    "    23:  \"Mitochondria\",   \n",
    "    24:  \"Aggresome\",   \n",
    "    25:  \"Cytosol\",   \n",
    "    26:  \"Cytoplasmic bodies\",   \n",
    "    27:  \"Rods & rings\"\n",
    "}\n",
    "\n",
    "#reversed dictionary (label_names)\n",
    "reverse_train_labels = dict((v,k) for k,v in label_names.items())\n",
    "\n",
    "# transform the list of targets of each sample into an array with 28 entries (number of classes) and each one can be 1\n",
    "# (in case of that class being present) or 0 (in case of that class being absent)\n",
    "def fill_targets(row):\n",
    "    row.Target = np.array(row.Target.split(\" \")).astype(np.int)\n",
    "    for num in row.Target:\n",
    "        name = label_names[int(num)]\n",
    "        row.loc[name] = 1\n",
    "    return row\n",
    "\n",
    "for key in label_names.keys():\n",
    "    train_labels[label_names[key]] = 0\n",
    "    \n",
    "train_labels = train_labels.apply(fill_targets, axis=1)\n",
    "\n",
    "# target_counts will be used to produce counts (more precisely, its values)\n",
    "target_counts = train_labels.drop([\"Id\", \"Target\"],axis=1).sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# auxiliary functions\n",
    "\n",
    "#used to see if every class already has absolute frequency bigger than a specific value, nmin\n",
    "def isGoalState(counts, nmin):\n",
    "    list_booleans = [i>=nmin for i in counts]\n",
    "    return all(item == True for item in list_booleans)\n",
    "\n",
    "# image augmentation as described on the report\n",
    "seq = iaa.Sequential([\n",
    "                iaa.OneOf([\n",
    "                    iaa.Fliplr(0.5), # horizontal flips\n",
    "                    iaa.Crop(percent=(0, 0.1)), # random crops\n",
    "                    # Small gaussian blur with random sigma between 0 and 0.5.\n",
    "                    # But we only blur about 50% of all images.\n",
    "                    iaa.Sometimes(0.5,\n",
    "                        iaa.GaussianBlur(sigma=(0, 0.5))\n",
    "                    ),\n",
    "                    # Strengthen or weaken the contrast in each image.\n",
    "                    iaa.ContrastNormalization((0.75, 1.5)),\n",
    "                    # Add gaussian noise.\n",
    "                    # For 50% of all images, we sample the noise once per pixel.\n",
    "                    # For the other 50% of all images, we sample the noise per pixel AND\n",
    "                    # channel. This can change the color (not only brightness) of the\n",
    "                    # pixels.\n",
    "                    iaa.AdditiveGaussianNoise(loc=0, scale=(0.0, 0.05*255), per_channel=0.5),\n",
    "                    # \n",
    "                    iaa.Multiply((0.8, 1.2), per_channel=0.2),\n",
    "                    # Apply affine transformations to each image.\n",
    "                    # Scale/zoom them, translate/move them, rotate them and shear them.\n",
    "                    iaa.Affine(\n",
    "                        scale={\"x\": (0.8, 1.2), \"y\": (0.8, 1.2)},\n",
    "                        translate_percent={\"x\": (-0.2, 0.2), \"y\": (-0.2, 0.2)},\n",
    "                        rotate=(-180, 180),\n",
    "                        shear=(-8, 8)\n",
    "                    )\n",
    "                ])], random_order=True)\n",
    "\n",
    "#intersection of two lists\n",
    "def intersection(lst1, lst2): \n",
    "    return list(set(lst1) & set(lst2)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialization\n",
    "\n",
    "data = pd.read_csv(DIR + '/train.csv')\n",
    "nmin = 20\n",
    "counts = target_counts.values\n",
    "print ('counts before oversampling:')\n",
    "print(counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_dataset(data, nmin, counts):\n",
    "    \n",
    "    new_data = pd.DataFrame.copy(data, deep=True)\n",
    "    samples_names = data['Id']\n",
    "    samples_labels = data['Target']\n",
    "    dataset_size = len(samples_names)\n",
    "    ncycle = 0\n",
    "    boolean = isGoalState(counts, nmin)\n",
    "    number_of_classes = counts.shape[0]\n",
    "    i=0\n",
    "    \n",
    "    \n",
    "    # while not every label has abs freq > nmin we'll keep ourselves cycling, where whenever we find a class that has \n",
    "    # lower abs freq than nmin, we copy that sample, but augmenting (applying some transformations), but keeping the \n",
    "    # target the same. At the same time, we're building a new .csv, where we're saving the link between the new samples\n",
    "    # and their target\n",
    "    \n",
    "    while not boolean:\n",
    "        \n",
    "        sample_name = samples_names[i]\n",
    "        sample_labels = samples_labels[i]\n",
    "        \n",
    "        sample_labels_list = sample_labels.split()\n",
    "        sample_labels_list = [int(item) for item in sample_labels_list]\n",
    "         \n",
    "        wanted = []\n",
    "        for j in range(number_of_classes):\n",
    "            if counts[j] < nmin:\n",
    "                wanted.append(j)\n",
    "        \n",
    "        if intersection(wanted, sample_labels_list) != []:\n",
    "            \n",
    "            filepath = path_to_train + sample_name\n",
    "            R = Image.open(filepath + '_red.png')\n",
    "            G = Image.open(filepath + '_green.png')\n",
    "            B = Image.open(filepath + '_blue.png')\n",
    "            Y = Image.open(filepath + '_yellow.png')\n",
    "\n",
    "            im = [np.array(R), np.array(G), np.array(B), np.array(Y)]\n",
    "            [new_R, new_G, new_B, new_Y] = seq.augment_images(im)\n",
    "            new_sample_name = sample_name + '_ia' + str(ncycle)\n",
    "\n",
    "            \n",
    "            im_saving_R = Image.fromarray(new_R)\n",
    "            im_saving_G = Image.fromarray(new_G)\n",
    "            im_saving_B = Image.fromarray(new_B)\n",
    "            im_saving_Y = Image.fromarray(new_Y)\n",
    "            \n",
    "            savepath = DIR + '/train_oversampling/'\n",
    "            im_saving_R.save(savepath + new_sample_name + '_red.png')\n",
    "            im_saving_G.save(savepath + new_sample_name + '_green.png')\n",
    "            im_saving_B.save(savepath + new_sample_name + '_blue.png')\n",
    "            im_saving_Y.save(savepath + new_sample_name + '_yellow.png')\n",
    "\n",
    "            df2 = pd.DataFrame({'Id': new_sample_name , 'Target': [sample_labels]})\n",
    "            new_data = new_data.append(df2, ignore_index=True )\n",
    "\n",
    "            for j in range(len(sample_labels_list)):\n",
    "                counts[sample_labels_list[j]] = counts[sample_labels_list[j]] + 1\n",
    "                    \n",
    "        if i == dataset_size - 1:\n",
    "            i = 0\n",
    "        else:\n",
    "            i=i+1\n",
    "        boolean = isGoalState(counts, nmin)\n",
    "        ncycle = ncycle + 1\n",
    "    print('new counts is:')\n",
    "    print(counts)\n",
    "    new_data.to_csv(DIR + '/train_oversampling/' + 'train_oversampling' + '.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RUN!\n",
    "new_dataset(data, nmin, counts)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
